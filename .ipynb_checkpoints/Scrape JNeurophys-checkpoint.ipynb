{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from requests import get\n",
    "import requests\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Journal of Neurophysiology is structured such that you can find all volume and issue information hidden on any of the volume pages, so we can just start with the first volume and create a list of links for the remaining volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_url = 'https://journals.physiology.org/loi/jn/group/d1940.y1940'\n",
    "url = start_url\n",
    "year = get(url)\n",
    "year_page = bs(year.text, 'html.parser')\n",
    "all_vol = year_page.find_all('a',{'href': re.compile(r'/toc/jn/')})\n",
    "vol_list = []\n",
    "for v in all_vol:\n",
    "    try: \n",
    "        vol_str = re.search(r'Volume\\s\\d{1,3}',str(v)).group()\n",
    "        vol_int = int(vol_str[7:])\n",
    "        vol_list.append(vol_int)\n",
    "    except AttributeError:\n",
    "        print('Something bad happened.')\n",
    "\n",
    "vol_list.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default digital open access starts in Volume 77, issue 1. Perhaps start the loop from this point instead of going through all of the earlier volumes, which are all paywalled and in PDF form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "open_access = [i for i in vol_list if i>76]\n",
    "print(open_access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_v = 0\n",
    "base_url = 'https://journals.physiology.org/toc/jn/'\n",
    "for v in open_access:\n",
    "    # count the issues in each volume\n",
    "    if v!=last_v:\n",
    "        issue=1\n",
    "    else:\n",
    "        issue+=1\n",
    "    \n",
    "    # construct the url for the issue and load it\n",
    "    issue_url = base_url + str(v) +'/' + str(issue)\n",
    "    print(issue_url)\n",
    "    get_issue = get(issue_url)\n",
    "    issue_page = bs(get_issue.text, 'html.parser')\n",
    "    issue_date = issue_page.find('div',{'class':'col-sm-4 gray-bg toc-right-side'}).\\\n",
    "        find('span',{'class':'coverDate'}).get_text()\n",
    "\n",
    "    # scrape all of the articles in this issue\n",
    "    toc = issue_page.find_all('div',{'class':'table-of-content'})[0].find_all('div',{'class':'issue-item'})\n",
    "\n",
    "    # loop through the articles\n",
    "    for c in toc:\n",
    "        section = dict()\n",
    "        \n",
    "        # check if article is behind a paywall. If so, skip it (for now)\n",
    "        if not c.find('div',{'class':'badges'}).get_text():\n",
    "            continue\n",
    "        \n",
    "        # get article metadata\n",
    "        art.url = 'https://journals.physiology.org' + c.find('a').get('href')\n",
    "        art.title = c.find('h4').text\n",
    "        auth = c.find('ul',{'class':'rlist--inline loa'}).find_all('li')\n",
    "        art.authors = [a.get_text().replace(', and ','') for a in auth]\n",
    "        art.doi = c.select(\".epub-section__item\")[0].find('a').get('href')[16:]\n",
    "        art.id = get_next_id(db_name, table_name) # still needs to be written\n",
    "        \n",
    "        # check if this article is already in database\n",
    "        # (currently, check the title for a match)\n",
    "        # if not, add metadata to table and load article. If so, continue loop.\n",
    "        if new_article_check(art.title): # still needs to be written\n",
    "            add_new_row(db_name, table_name, art)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # load article\n",
    "        get_art = get(art.url)\n",
    "        art_page = bs(get_art, 'html.parser')\n",
    "        \n",
    "        # get reference list\n",
    "        rlist = art_page.find('ul',{'class':'rlist separator'}).find_all('li')\n",
    "        # loop through references and add them to database\n",
    "        for r in rlist:\n",
    "            r.url = [i.get('href') for i in r.find_all('a')]\n",
    "            r.title = r.find('span',{'class':'references__article-title'}).get_text()\n",
    "            r.authors = r.find('span',{'class':'references__authors'}).get_text().split(', ')\n",
    "            r.id = get_next_id(db_name, table_name) # still needs to be written\n",
    "            \n",
    "            # check if article is in database\n",
    "            if new_article_check(art.title): # still needs to be written\n",
    "                add_new_row(db_name, table_name, r)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # add the citation\n",
    "            # This function should add the citing ID to a list of citing IDs in the entry for the cited ID\n",
    "            # It should also add the cited ID to a list of cited IDs in the entry for the citing ID\n",
    "            add_citation_to_DB(citing_ID = art.id, cited_ID = r.id)\n",
    "            \n",
    "            \n",
    "        # get article sections\n",
    "        # get abstract\n",
    "        section{'Abstract'} = art_page.select('div.hlFld-Abstract div.abstractSection')[0].get_text()\n",
    "        # get all other sections\n",
    "        section['Introduction'] = ''\n",
    "        fulltext = test_page.find('div', {'class': 'hlFld-Fulltext'}).findChildren(recursive=False)\n",
    "        for f in fulltext:\n",
    "            heading = f.find('h1',{'class':'article-section__title section__title'})\n",
    "            if not heading:\n",
    "                section['Introduction']  = section['Introduction']  + ' ' + f.find_text()\n",
    "            else:\n",
    "                section[heading.get_text()] = ''\n",
    "                for text in heading.find_parent().findChildren('div'):\n",
    "                    section[heading.get_text()] = section[heading.get_text()] + text.get_text()\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Brainstorming:\n",
    "* Have a function that cycles through the DB, checks for entries with no text, and tries to find the text via PubMed (with the PubMed parser) or with Google Scholar\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing stuff out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# page = get('https://journals.physiology.org/doi/full/10.1152/jn.00104.2016')\n",
    "page = get('https://journals.physiology.org/doi/full/10.1152/jn.00399.2013')\n",
    "test_page = bs(page.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loa = test_page.find('div',{'class':'accordion-tabbed loa-accordion'}).\\\n",
    "find_all('div',{'class':'accordion-tabbed__tab-mobile '})\n",
    "[i.find('a').get_text() for i in loa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_page.select('div.cover-image__details ')[0].find('span',{'class':'volume'}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_page.select('div.cover-image__details ')[0].find('span',{'class':'issue'}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int(test_page.select('div.cover-image__details ')[0].\\\n",
    "            find('span', {'class': 'coverDate'}).get_text()[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fulltext = test_page.find('div', {'class': 'hlFld-Fulltext'}).findChildren(recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fulltext[7].find('h1',{'class':'article-section__title section__title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "refs = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "section = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "section[fulltext[7].find('h1',{'class':'article-section__title section__title'}).get_text()] = 'hi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sec_text = fulltext[7].find('h1',{'class':'article-section__title section__title'}).find_parent().findChildren('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heading = fulltext[7].find('h1',{'class':'article-section__title section__title'})\n",
    "section[heading.get_text()] = ''\n",
    "for text in heading.find_parent().findChildren('div'):\n",
    "    section[heading.get_text()] = section[heading.get_text()] + text.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out pymysql with Amazon RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import journal_scrape as js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -U PyMySQL\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = js.Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dbname = \"findingssm\"\n",
    "# host = \"findingssm.c9zjgwsivgee.us-east-2.rds.amazonaws.com\"\n",
    "# port = 3306\n",
    "# user = \"danielkentwood\"\n",
    "# password = \"findingsdbsm\"\n",
    "\n",
    "# conn = pymysql.connect(host, user=user, port=port, passwd=password, db=dbname, connect_timeout=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "    CREATE TABLE [IF NOT EXISTS] metadata (\n",
    "    id INT,\n",
    "    url VARCHAR(255),\n",
    "    year YEAR,\n",
    "    volume INT,\n",
    "    issue INT,\n",
    "    title VARCHAR(255),\n",
    "    authors VARCHAR(255),\n",
    "    doi VARCHAR(255)\n",
    ");'''\n",
    "\n",
    "db.cursor(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "    CREATE TABLE [IF NOT EXISTS] text (\n",
    "    id INT,\n",
    "    sectionA VARCHAR(255),\n",
    "    sectionB VARCHAR(255),\n",
    "    text VARCHAR(255)\n",
    ");'''\n",
    "\n",
    "db.cursor(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbclass import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not connect to server: Operation timed out\n\tIs the server running on host \"findingspostgres.c9zjgwsivgee.us-east-2.rds.amazonaws.com\" (18.191.86.254) and accepting\n\tTCP/IP connections on port 5432?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a6c0b3ffabc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/SharpestMindsProject/dbclass.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDatabase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/SharpestMindsProject/dbclass.py\u001b[0m in \u001b[0;36mget_database\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection_from_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connected to PostgreSQL database.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/SharpestMindsProject/dbclass.py\u001b[0m in \u001b[0;36mget_connection_from_profile\u001b[0;34m(self, config_file_name)\u001b[0m\n\u001b[1;32m     41\u001b[0m         return self.get_connection(vals['DBNAME'], vals['USER'],\n\u001b[1;32m     42\u001b[0m                                    \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOST'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PORT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                    vals['PASSWORD'])\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasswd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/SharpestMindsProject/dbclass.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(self, db, user, host, port, passwd)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mconn_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"host=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" port=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" dbname=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m\" user=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" password=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpasswd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not connect to server: Operation timed out\n\tIs the server running on host \"findingspostgres.c9zjgwsivgee.us-east-2.rds.amazonaws.com\" (18.191.86.254) and accepting\n\tTCP/IP connections on port 5432?\n"
     ]
    }
   ],
   "source": [
    "db = Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
